{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Chatbot_Test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrkfhAQ1Rf6yAe6ZlS9R0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chubbyman2/Clarisse/blob/master/Pytorch_Clarisse_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko025FColVpq",
        "outputId": "f6dfaebb-8efe-433c-cf31-2e676025cae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwi10PXFi_tY",
        "outputId": "3e1e595f-17d7-4128-b277-ced6ba3d903a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\") # Package with a pre-trained tokenizer\n",
        "from nltk.stem.porter import PorterStemmer # Import stemmer\n",
        "stemmer = PorterStemmer()\n",
        "import numpy as np"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1TQRKnu7i-n"
      },
      "source": [
        "**Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4wogK0Qk8c6"
      },
      "source": [
        "def tokenize(sentence):\n",
        "  return nltk.word_tokenize(sentence)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il__UVVok_I6"
      },
      "source": [
        "def stem(word):\n",
        "  return stemmer.stem(word.lower())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYVaCxjllAQA"
      },
      "source": [
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "  '''\n",
        "  sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "  words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "  bag =   [ 0 ,    1   ,  0 ,   1  ,   0  ,    0   ,    0  ]\n",
        "  '''\n",
        "  tokenized_sentence = [stem(w) for w in tokenized_sentence]\n",
        "\n",
        "  bag = np.zeros(len(all_words), dtype=np.float32)\n",
        "  for idx, w in enumerate(all_words):\n",
        "    if w in tokenized_sentence:\n",
        "      bag[idx] = 1.0\n",
        "    \n",
        "  return bag"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ORCz4klFMI",
        "outputId": "541a56cc-7f8c-4435-a7b3-82c88822904c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tokenization test\n",
        "test = \"How are you?\"\n",
        "print(tokenize(test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['How', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znmD2Gb7mLfS",
        "outputId": "407c0e60-b080-48ba-a4a1-47d98f8d32f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Stemming test\n",
        "test_words = [\"Universal\", \"university\", \"universe\"]\n",
        "stemmed_words = [stem(w) for w in test_words]\n",
        "print(stemmed_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['univers', 'univers', 'univers']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlM3VFp3sTTZ",
        "outputId": "94147f45-7e91-4c8f-8dc7-47200a58e459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Bag of words test\n",
        "sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "bag = bag_of_words(sentence, words)\n",
        "print(bag)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFsc85zBqWHP"
      },
      "source": [
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPswIiIAnVQD",
        "outputId": "d77c9fdc-b4d8-48e5-cbb8-8853b8376f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvIeCCfGnTy4",
        "outputId": "7647def9-27fb-4814-aab7-b5dbd620bac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/intents.json\", \"r\") as file:\n",
        "  intents = json.load(file)\n",
        "\n",
        "print(intents)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87UuLanRoCM6"
      },
      "source": [
        "all_words = []\n",
        "tags = []\n",
        "word_and_tag = []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "  tag = intent[\"tag\"]\n",
        "  tags.append(tag)\n",
        "  for pattern in intent[\"patterns\"]:\n",
        "    w = tokenize(pattern)\n",
        "    all_words.extend(w)\n",
        "    word_and_tag.append((w, tag))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ojmhIcWpB9X",
        "outputId": "9326b0cf-344f-4a1f-da28-3085e3cd774f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ignore_words = [\"?\", \"!\", \".\", \",\"]\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words] # Stems all the words\n",
        "all_words = sorted(set(all_words)) # All unique words, sorted in order\n",
        "print(all_words) # Prints unique, stemmed words\n",
        "\n",
        "tags = sorted(set(tags))\n",
        "print(tags)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodbi', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n",
            "['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXNGoOOHpmZ_"
      },
      "source": [
        "x_train = [] \n",
        "y_train = []\n",
        "\n",
        "for (pattern_sentence, tag) in word_and_tag:\n",
        "  bag = bag_of_words(pattern_sentence, all_words)\n",
        "  x_train.append(bag)\n",
        "\n",
        "  label = tags.index(tag)\n",
        "  y_train.append(label)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXV52l6vtDVd"
      },
      "source": [
        "**Pytorch Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0BS0XvMtFNw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_uGS9wvtOsk"
      },
      "source": [
        "class ChatDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.n_samples = len(x_train)\n",
        "    self.x_data = x_train\n",
        "    self.y_data = y_train\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psEkhNKsvXOH",
        "outputId": "8945ccc3-2885-4bf6-9b35-cf93a68f4086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set hyperparameters\n",
        "batch_size = 8\n",
        "hidden_size = 8\n",
        "input_size = len(all_words)\n",
        "output_size = len(tags)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1000\n",
        "\n",
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "print(input_size, output_size)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54 54 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYA5OcDEuUCM"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.l3(out) \n",
        "    # No activation, no softmax\n",
        "    return out"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnEmHRBvNke"
      },
      "source": [
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkCFwAVxv_tf"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYOjbvXQwEnI",
        "outputId": "c188a892-cec5-4463-ac99-c05a96c536dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for (words, labels) in train_loader:\n",
        "    words = words.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(words)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass, optimizer step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # Backpropagation\n",
        "    optimizer.step()\n",
        "\n",
        "  # Every 100 steps\n",
        "  if (epoch + 1) % 100 == 0:\n",
        "    print(f\"epoch {epoch+1}/{num_epochs}, loss={loss.item():.4f}\")\n",
        "\n",
        "print(f\"Final loss = {loss.item():.4f}\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 100/1000, loss=0.0000\n",
            "epoch 200/1000, loss=0.0000\n",
            "epoch 300/1000, loss=0.0000\n",
            "epoch 400/1000, loss=0.0000\n",
            "epoch 500/1000, loss=0.0000\n",
            "epoch 600/1000, loss=0.0000\n",
            "epoch 700/1000, loss=0.0000\n",
            "epoch 800/1000, loss=0.0000\n",
            "epoch 900/1000, loss=0.0000\n",
            "epoch 1000/1000, loss=0.0000\n",
            "Final loss = 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGvOUTQn3S0t",
        "outputId": "47645026-88de-47fc-8891-9b73967932de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"input_size\": input_size,\n",
        "    \"output_size\": output_size,\n",
        "    \"hidden_size\": hidden_size,\n",
        "    \"all_words\": all_words,\n",
        "    \"tags\": tags\n",
        "}\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f\"Training complete, file saved to {FILE}\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training complete, file saved to data.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4cbdb58c-a8fa-48ab-8800-63b0223fc407\", \"data.pth\", 5255)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysfjfZGC4Ctv"
      },
      "source": [
        "# Download pickled file\n",
        "from google.colab import files\n",
        "files.download('data.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4b5brAy4NZd"
      },
      "source": [
        "**Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b64uiZyV4F4o"
      },
      "source": [
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data[\"all_words\"]\n",
        "tags = data[\"tags\"]\n",
        "model_state = data[\"model_state\"]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB0rzowg4gFA",
        "outputId": "b46c02e4-e90a-497e-d93e-f1ea6c6145d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(model_state)\n",
        "model.eval()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wUM6KVr4kAQ",
        "outputId": "f2da5415-0d33-4aa6-9607-56f1326eb1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "name = \"Clarisse\"\n",
        "print(\"Hello there! Let's talk. \\nP.S. Type 'quit' to exit.\")\n",
        "\n",
        "while True:\n",
        "  sentence = input(\"You: \")\n",
        "  if sentence == \"quit\":\n",
        "    break\n",
        "\n",
        "  # Tokenize sentence\n",
        "  sentence = tokenize(sentence)\n",
        "\n",
        "  # Create bag of words\n",
        "  x = bag_of_words(sentence, all_words)\n",
        "  x = x.reshape(1, x.shape[0]) \n",
        "  x = torch.from_numpy(x) # Convert to torch tensor\n",
        "\n",
        "  output = model(x)\n",
        "\n",
        "  _, predicted = torch.max(output, dim=1)\n",
        "  tag = tags[predicted.item()] # tags[class label]\n",
        "\n",
        "  probs = torch.softmax(output, dim=1)\n",
        "  prob = probs[0][predicted.item()]\n",
        "\n",
        "  if prob.item() > 0.75: # Only returns a response if the confidence is >0.75\n",
        "    for intent in intents[\"intents\"]:\n",
        "      if tag == intent[\"tag\"]:\n",
        "        print(f\"{name}: {random.choice(intent['responses'])}\") # Gets a random response\n",
        "  \n",
        "  else:\n",
        "    print(f\"{name}: I do not understand...\")\n",
        "    "
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello there! Let's talk. \n",
            "P.S. Type 'quit' to exit.\n",
            "You: hello\n",
            "Clarisse: Hello, thanks for visiting\n",
            "You: how are you\n",
            "Clarisse: Hello, thanks for visiting\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}